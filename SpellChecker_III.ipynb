{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta parte continuaremos con la implementación eficiente de nuestro *modelo del lenguaje* basado en trigramas.\n",
    "\n",
    "En el artículo anterior definimos que era un *modelo del lenguaje* la teoría necesaria para construir un modelo del lenguaje basado en n-gramas y tratamos de hacer una primera implementación utilizando una matriz como estructura de datos, lo cuál no se pudo realizar debido a la gran cantidad de memoria que sería requerida por este tipo de implementación. Esta vez utilizaremos diccionarios como estructuras de datos buscando una manera más eficiente de implementar nuestro modelo.\n",
    "\n",
    "Comenzaremos repasando el código que hemos escrito hasta ahora para cargar nuestro corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "\n",
    "text = ''\n",
    "\n",
    "for i in range(1, 202):\n",
    "    text += (open('CORPUS/{}.txt'.format(i)).read().split('Contenido:')[-1])\n",
    "    \n",
    "def clean_text(text):\n",
    "    text = re.sub(r'\\n', '. ', text)\n",
    "    text = re.sub(r'[{}@_*<>()\\\\#%+=\\[\\]ôà|è$–/—‘’«°º»”“&…∑⁄]', '', text)\n",
    "    text = re.sub('a0', '', text)\n",
    "    text = re.sub('\\'92t', '\\'t', text)\n",
    "    text = re.sub('\\'92s', '\\'s', text)\n",
    "    text = re.sub('\\'92m', '\\'m', text)\n",
    "    text = re.sub('\\'92ll', '\\'ll', text)\n",
    "    text = re.sub('\\'91', '', text)\n",
    "    text = re.sub('\\'92', '', text)\n",
    "    text = re.sub('\\'93', '', text)\n",
    "    text = re.sub('\\'94', '', text)\n",
    "    text = re.sub('\\uf0b7', '', text)\n",
    "    text = re.sub('\\uf0e0', '', text)\n",
    "    text = re.sub('\\u200e', '', text)\n",
    "    text = re.sub('\\ufeff', '', text)\n",
    "    text = re.sub('\\u200b', '', text)\n",
    "    text = re.sub('\\t', '', text)\n",
    "    text = re.sub('\\r', '', text)\n",
    "    text = re.sub('\\.', '. ', text)\n",
    "    text = re.sub('\\!', '! ', text)\n",
    "    text = re.sub('\\?', '? ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "text = clean_text(text)\n",
    "\n",
    "text = text.replace('.', ' _ _ ')\n",
    "\n",
    "vocab = sorted(set(re.findall('[A-Za-z_áéíóúüñ]+', text)))\n",
    "\n",
    "word2id = { word:i for i, word in enumerate(vocab) }\n",
    "\n",
    "id2word = np.array(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extrayendo trigramas y construyendo el modelo\n",
    "\n",
    "Para la construcción de nuestro modelo primeramente procederemos a los trigramas el corpus para lo que se define la siguiente función:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trigrams(text):\n",
    "    # Lista para almacenar los trigramas\n",
    "    trigrams = []\n",
    "    \n",
    "    # Segmentar el texto por palabras\n",
    "    words = re.findall('[A-Za-z_áéíóúüñ]+', text)\n",
    "    \n",
    "    # Recorrer la lista de palabras\n",
    "    for i in range(len(words)-2):\n",
    "        # Extraer trigramas de la lista de palabras\n",
    "        w1, w2, w3 = words[i:i+3]\n",
    "        \n",
    "        # Convertir palabras a su id correspondiente\n",
    "        w1 = word2id[w1]\n",
    "        w2 = word2id[w2]\n",
    "        w3 = word2id[w3]\n",
    "        \n",
    "        # Agregar trigrama a la lista\n",
    "        trigrams.append((w1, w2, w3))\n",
    "    \n",
    "    return trigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trigrams = get_trigrams(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74792"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2889, 2889, 1516),\n",
       " (2889, 1516, 8656),\n",
       " (1516, 8656, 6332),\n",
       " (8656, 6332, 11700),\n",
       " (6332, 11700, 11035),\n",
       " (11700, 11035, 5259),\n",
       " (11035, 5259, 4928),\n",
       " (5259, 4928, 9212),\n",
       " (4928, 9212, 8037),\n",
       " (9212, 8037, 7781)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trigrams[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos una lista con todos los trigramas extraídos de nuestro corpus, el hecho de utilizar el id de las palabras en lugar del texto nos permite ahorrar memoria además de facilitarnos la indexación como veremos a continuación.\n",
    "\n",
    "#### Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializamos el modelo (es un diccionario)\n",
    "model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contamos la frecuencia de co-ocurrencia\n",
    "for i in range(len(trigrams)):\n",
    "    w1, w2, w3 = trigrams[i]\n",
    "    \n",
    "    # El control de excepciones se encarga de manejar los distintos casos \n",
    "    # en que un trigrama aún no ha sido registrado.\n",
    "    try:\n",
    "        model[w1, w2][w3] += 1\n",
    "    except: # Aqui se asume que w3 lanza la excepcion\n",
    "        try:\n",
    "            model[w1, w2][w3] = 1\n",
    "        except: # Aqui se asume que el par (w1, w2) lanza la excepcion\n",
    "            model[w1, w2] = {w3:1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las instrucciones anteriores lo que hacen es recorrer nuestra lista de trigramas e ir extrayendo cada una de las palabras que lo conforman. El diccionario que utilizamos como estructura de datos almacenará como llave las dos primeras palabras del trigrama y como valor un nuevo diccionario que tendrá como llave la tercera palabra del trigrama y como valor el número de veces que se repite el trigrama.\n",
    "\n",
    "La primera instrucción `model[w1, w2][w3] += 1` asume que ya el trigrama completo ha sido registrado en cuyo caso solo es necesario aumentar el contador, en caso contrario se lanza una excepción y se procede a ejecutar la siguiente instrucción: `model[w1, w2][w3] = 1`, esta instrucción asume que se ha registrado ya una llave `(w1,w2)` para el primer diccionario, en este caso se procede a registrar la llave `w3` para el segundo diccionario y se inicializa su valor 1 indicando que es primera vez que se registra el trigrama. En caso de que no se hallan registrado ninguna de las llaves para ninguno de los dos diccionarios se lanzará nuevamente una excepción y se procede a registrar ambas llaves y a inicializar su valor igualmente con 1 utilizando la instrucción: `model[w1, w2] = {w3:1}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora transformamos el conteo en probabilidades\n",
    "for w1_w2 in model:\n",
    "    total_count = float(sum(model[w1_w2].values()))\n",
    "    \n",
    "    for w3 in model[w1_w2]:\n",
    "        model[w1_w2][w3] /= total_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta instrucción lo que hacemos es obtener las probabilidades de ocurrencia de cada trigrama. Recorando la hipotesis markoviana $P(w_n|w_1^{n-1})$ se puede estimar como $P(w_n|w_{n-2}^{n-1})$.\n",
    "\n",
    "Nuestro objetivo con la construcción de este modelo es poder decir dadas dos palabras cuál es la probabilidad de ocurrencia de una tercera. Probabilidad que será utlizada por nuestro corrector para ordenar las sugerencias generadas.\n",
    "\n",
    "Y así finalmente tenemos construido nuestro modelo del lenguaje estadístico basado en trigramas.\n",
    "\n",
    "Ahora por ejemplo determinemos cual es la probabilidad del siguiente trigrama extraído del corpus:\n",
    "\n",
    "    definición del bien"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = \"definición del bien\"\n",
    "\n",
    "w1, w2, w3 = sentence.split()\n",
    "\n",
    "model[word2id[w1], word2id[w2]][word2id[w3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Que significa esto?, esto significa que dadas las palabras \"definición\" y \"del\" en ese orden la probabilidad de que la tercera palabra sea \"bien\" es de 0.5 la cuál es una probabilidad alta y para este caso quiere decir que en nuestro corpus solamente existen dos palabras que vienen despues de la cadena \"definición del\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2 = model[word2id[w1], word2id[w2]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bien'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[w1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'año'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[w2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debemos señalar que los datos del modelo creado o sea los trigramas registrados y sus probabilidades de ocurrencia dependen del corpus que utilizemos, todos sabemos que después de la cadena \"definición del\" pueden ocurrir muchísimas palabras más pero en este caso solamente tenemos dos que han sido extraídas de nuestro corpus.\n",
    "\n",
    "Con esto podemos decir que nuestro modelo del lenguaje esta listo, en el próximo artículo trabajaremos en la siguiente tarea requerida para la implementación de nuestro corrector estadístico: **generación de sugerencias por transformaciones de caracteres en base a inserciones, eliminaciones, sustituciones y transposición**."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
